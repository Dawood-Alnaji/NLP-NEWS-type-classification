# NLP-NEWS-type-classification
This project revolves around training different sequential models and transformer based pretrained ones to train on News to be able to predict its type

The models used are:
1- Naive bayes and decision tree as normal machine learning models
2- BiDirectional LSTM as a sequential model
3- BERT pretrained classification model as a transformer based model

Word embedding methods used were: 
1- TF-IDF
2- Word2vec
3- BERT embeddings
